{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import math\n",
    "\n",
    "import myImageLibrary\n",
    "\n",
    "from tensorflow.saved_model import simple_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def showimage(title,img):\n",
    "    cv2.imshow(title,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def crop_center(image,cropx,cropy):\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    startx = w//2-(cropx//2)\n",
    "    starty = h//2-(cropy//2)\n",
    "    return image[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "def resize_crop(image,square_size):\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    min_dim = min(w,h)  \n",
    "    max_square_image = crop_center(image, min_dim, min_dim)\n",
    "    result = cv2.resize(max_square_image,(square_size,square_size),0,0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classifier_data(image_folder, size = 256, verbose = True, mode = \"channels_first\",one_hot = False):\n",
    "    \n",
    "    folders = os.listdir(\"images\")\n",
    "    if verbose:\n",
    "        print(\"classes: {0}\".format(folders))\n",
    "    input_labels = []\n",
    "    input_data = []\n",
    "    label_dict = {}\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        if verbose:\n",
    "            print(\"{0}..\".format(folder))   \n",
    "        image_list = myImageLibrary.get_images(os.path.join(\"images\",folder))\n",
    "        if mode == \"channels_first\":\n",
    "            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size).transpose(2,0,1)/255.0,decimals=12) for image in image_list]\n",
    "        elif mode == \"channels_last\":\n",
    "            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size)/255.0,decimals=12) for image in image_list]\n",
    "        else:\n",
    "            print(\"invalid mode. pick channels_first or channels_last\")\n",
    "        # processed = normalized, resized and cropped, transposed to \"channels first\"\n",
    "        input_labels = input_labels+([i]*len(processed_image_list))\n",
    "        input_data = input_data+processed_image_list\n",
    "        label_dict[str(i)] = folder\n",
    "        \n",
    "    shape = list(input_data[0].shape)\n",
    "    shape[:0] = [len(input_data)]\n",
    "    input_array = np.concatenate(input_data).reshape(shape)\n",
    "    \n",
    "    input_labels = np.array(input_labels)\n",
    "    \n",
    "    if one_hot:\n",
    "        input_labels = convert_to_one_hot(np.array(input_labels),len(folders)).T\n",
    "            \n",
    "    return input_array, input_labels, label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['car', 'plane', 'train']\n",
      "car..\n",
      "plane..\n",
      "train..\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"images\"\n",
    "input_images, labels, label_dict = get_classifier_data(image_folder,mode=\"channels_last\",one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(518, 256, 256, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_images.shape)\n",
    "print(labels.shape)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input_images,labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result_car = glob.glob('fotos_auto/*.jpg')+glob.glob('fotos_auto/*.jpeg')+glob.glob('fotos_auto/*.png')\n",
    "images_car = [cv2.imread(item) for item in result_car]\n",
    "print(len(images_car))\n",
    "images_car = images_car[1:] #because first item appears to be None\n",
    "\n",
    "result_plane = glob.glob('fotos_vliegtuig/*.jpg')+glob.glob('fotos_vliegtuig/*.jpeg')+glob.glob('fotos_vliegtuig/*.png')\n",
    "images_plane = [cv2.imread(item) for item in result_plane]\n",
    "print(len(images_plane))\n",
    "\n",
    "result_train = glob.glob('fotos_trein/*.jpg')+glob.glob('fotos_trein/*.jpeg')+glob.glob('fotos_trein/*.png')\n",
    "images_train = [cv2.imread(item) for item in result_train]\n",
    "print(len(images_train))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "average_min_dim = 256\n",
    "\n",
    "# rescaling and cropping images\n",
    "\n",
    "resized_images_car = np.array([resize_crop(item,average_min_dim) for item in images_car])\n",
    "resized_images_plane = np.array([resize_crop(item,average_min_dim) for item in images_plane])\n",
    "resized_images_train = np.array([resize_crop(item,average_min_dim) for item in images_train])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# combine all data, labels, normalize and make a train-test split\n",
    "\n",
    "input_images = np.append(np.append(resized_images_car,resized_images_plane,axis=0),resized_images_train,axis=0)/255\n",
    "labels = np.array([0] * resized_images_car.shape[0] + [1] * resized_images_plane.shape[0] + [2] * resized_images_train.shape[0])\n",
    "labels = np.reshape(labels,(-1,1))\n",
    "outputy = convert_to_one_hot(labels,3).T\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(input_images,outputy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(388, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.4745098 , 0.52156863, 0.52941176],\n",
       "         [0.47843137, 0.52156863, 0.52941176],\n",
       "         [0.47843137, 0.51764706, 0.52941176],\n",
       "         ...,\n",
       "         [0.60392157, 0.65098039, 0.65882353],\n",
       "         [0.60784314, 0.65490196, 0.6627451 ],\n",
       "         [0.61568627, 0.6627451 , 0.67058824]],\n",
       "\n",
       "        [[0.47843137, 0.5254902 , 0.53333333],\n",
       "         [0.48235294, 0.52941176, 0.5372549 ],\n",
       "         [0.49019608, 0.52941176, 0.5372549 ],\n",
       "         ...,\n",
       "         [0.61176471, 0.65882353, 0.66666667],\n",
       "         [0.61176471, 0.65882353, 0.66666667],\n",
       "         [0.61568627, 0.6627451 , 0.67058824]],\n",
       "\n",
       "        [[0.49019608, 0.5372549 , 0.54509804],\n",
       "         [0.49411765, 0.54117647, 0.54901961],\n",
       "         [0.49803922, 0.54117647, 0.54901961],\n",
       "         ...,\n",
       "         [0.60392157, 0.65098039, 0.65882353],\n",
       "         [0.60392157, 0.65098039, 0.65882353],\n",
       "         [0.61176471, 0.65882353, 0.6627451 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.12156863, 0.31372549, 0.36862745],\n",
       "         [0.12156863, 0.31764706, 0.36862745],\n",
       "         [0.11372549, 0.32156863, 0.36862745],\n",
       "         ...,\n",
       "         [0.0745098 , 0.28627451, 0.3372549 ],\n",
       "         [0.07843137, 0.28627451, 0.3372549 ],\n",
       "         [0.07843137, 0.28627451, 0.3372549 ]],\n",
       "\n",
       "        [[0.07058824, 0.2745098 , 0.32156863],\n",
       "         [0.07058824, 0.27058824, 0.31764706],\n",
       "         [0.0627451 , 0.27058824, 0.31764706],\n",
       "         ...,\n",
       "         [0.07058824, 0.28627451, 0.3372549 ],\n",
       "         [0.07058824, 0.28627451, 0.3372549 ],\n",
       "         [0.07058824, 0.28627451, 0.3372549 ]],\n",
       "\n",
       "        [[0.03137255, 0.23921569, 0.28627451],\n",
       "         [0.02745098, 0.23921569, 0.28235294],\n",
       "         [0.02745098, 0.24313725, 0.28235294],\n",
       "         ...,\n",
       "         [0.09411765, 0.30980392, 0.36078431],\n",
       "         [0.09019608, 0.30588235, 0.35686275],\n",
       "         [0.08627451, 0.30196078, 0.35294118]]],\n",
       "\n",
       "\n",
       "       [[[0.81568627, 0.5254902 , 0.30588235],\n",
       "         [0.81568627, 0.5254902 , 0.30588235],\n",
       "         [0.81568627, 0.5254902 , 0.30588235],\n",
       "         ...,\n",
       "         [0.82352941, 0.53333333, 0.31372549],\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         [0.82352941, 0.53333333, 0.31372549]],\n",
       "\n",
       "        [[0.80784314, 0.51764706, 0.29803922],\n",
       "         [0.81568627, 0.5254902 , 0.30588235],\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         ...,\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         [0.81568627, 0.5254902 , 0.30588235],\n",
       "         [0.81960784, 0.52941176, 0.30980392]],\n",
       "\n",
       "        [[0.82352941, 0.53333333, 0.31372549],\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         ...,\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         [0.81960784, 0.52941176, 0.30980392],\n",
       "         [0.81960784, 0.52941176, 0.30980392]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.79215686, 0.54901961, 0.36078431],\n",
       "         [0.79215686, 0.54901961, 0.36078431],\n",
       "         [0.79215686, 0.54901961, 0.36078431],\n",
       "         ...,\n",
       "         [0.78823529, 0.55294118, 0.37254902],\n",
       "         [0.78823529, 0.55294118, 0.37254902],\n",
       "         [0.78823529, 0.55294118, 0.37254902]],\n",
       "\n",
       "        [[0.79215686, 0.54901961, 0.36078431],\n",
       "         [0.79215686, 0.54901961, 0.36078431],\n",
       "         [0.79215686, 0.54901961, 0.36078431],\n",
       "         ...,\n",
       "         [0.79215686, 0.55686275, 0.37647059],\n",
       "         [0.79215686, 0.55686275, 0.37647059],\n",
       "         [0.79215686, 0.55686275, 0.37647059]],\n",
       "\n",
       "        [[0.8       , 0.54901961, 0.36078431],\n",
       "         [0.8       , 0.54901961, 0.36078431],\n",
       "         [0.80392157, 0.55294118, 0.37254902],\n",
       "         ...,\n",
       "         [0.79215686, 0.55294118, 0.37647059],\n",
       "         [0.79607843, 0.55686275, 0.37647059],\n",
       "         [0.8       , 0.55686275, 0.36078431]]],\n",
       "\n",
       "\n",
       "       [[[0.99607843, 0.80392157, 0.57254902],\n",
       "         [1.        , 0.79607843, 0.56078431],\n",
       "         [1.        , 0.79607843, 0.56078431],\n",
       "         ...,\n",
       "         [0.98823529, 0.81568627, 0.69411765],\n",
       "         [0.97647059, 0.80392157, 0.68235294],\n",
       "         [0.97647059, 0.80784314, 0.68627451]],\n",
       "\n",
       "        [[1.        , 0.78431373, 0.56862745],\n",
       "         [1.        , 0.78431373, 0.56078431],\n",
       "         [1.        , 0.79607843, 0.57647059],\n",
       "         ...,\n",
       "         [0.97647059, 0.81568627, 0.69019608],\n",
       "         [0.98431373, 0.81176471, 0.69803922],\n",
       "         [0.97254902, 0.80784314, 0.68235294]],\n",
       "\n",
       "        [[1.        , 0.78039216, 0.56862745],\n",
       "         [1.        , 0.78431373, 0.56078431],\n",
       "         [1.        , 0.78823529, 0.56470588],\n",
       "         ...,\n",
       "         [0.98431373, 0.81176471, 0.69019608],\n",
       "         [0.98039216, 0.81176471, 0.69019608],\n",
       "         [0.98039216, 0.81960784, 0.69803922]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.26666667, 0.18823529, 0.15686275],\n",
       "         [0.29803922, 0.20392157, 0.15686275],\n",
       "         [0.2745098 , 0.2       , 0.18039216],\n",
       "         ...,\n",
       "         [0.44313725, 0.42352941, 0.43137255],\n",
       "         [0.55686275, 0.54509804, 0.55294118],\n",
       "         [0.61176471, 0.61568627, 0.62745098]],\n",
       "\n",
       "        [[0.22745098, 0.14509804, 0.09019608],\n",
       "         [0.25882353, 0.16862745, 0.10980392],\n",
       "         [0.2745098 , 0.16470588, 0.12156863],\n",
       "         ...,\n",
       "         [0.10196078, 0.0627451 , 0.02352941],\n",
       "         [0.1254902 , 0.09803922, 0.08627451],\n",
       "         [0.28627451, 0.26666667, 0.27058824]],\n",
       "\n",
       "        [[0.30980392, 0.24705882, 0.20784314],\n",
       "         [0.38823529, 0.33333333, 0.31372549],\n",
       "         [0.36078431, 0.31372549, 0.29411765],\n",
       "         ...,\n",
       "         [0.09411765, 0.05882353, 0.04313725],\n",
       "         [0.10588235, 0.07058824, 0.05882353],\n",
       "         [0.14509804, 0.10196078, 0.09019608]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.61568627, 0.50588235, 0.43529412],\n",
       "         [0.62745098, 0.49803922, 0.38431373],\n",
       "         [0.63137255, 0.48235294, 0.34509804],\n",
       "         ...,\n",
       "         [0.32941176, 0.62352941, 0.63529412],\n",
       "         [0.34901961, 0.62745098, 0.62352941],\n",
       "         [0.31372549, 0.59215686, 0.58039216]],\n",
       "\n",
       "        [[0.5372549 , 0.51372549, 0.52156863],\n",
       "         [0.57647059, 0.55294118, 0.52941176],\n",
       "         [0.58039216, 0.54117647, 0.48627451],\n",
       "         ...,\n",
       "         [0.15686275, 0.62352941, 0.6627451 ],\n",
       "         [0.08627451, 0.61568627, 0.63921569],\n",
       "         [0.03529412, 0.57647059, 0.59215686]],\n",
       "\n",
       "        [[0.46666667, 0.49411765, 0.53333333],\n",
       "         [0.48235294, 0.5372549 , 0.56078431],\n",
       "         [0.51764706, 0.56470588, 0.56078431],\n",
       "         ...,\n",
       "         [0.06666667, 0.57647059, 0.63529412],\n",
       "         [0.00392157, 0.56470588, 0.62745098],\n",
       "         [0.        , 0.51764706, 0.57647059]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784314, 0.4745098 , 0.08235294],\n",
       "         [0.81176471, 0.47843137, 0.08627451],\n",
       "         [0.81176471, 0.47843137, 0.09019608],\n",
       "         ...,\n",
       "         [0.80392157, 0.48627451, 0.10588235],\n",
       "         [0.80784314, 0.48627451, 0.10980392],\n",
       "         [0.80392157, 0.48235294, 0.10980392]],\n",
       "\n",
       "        [[0.80784314, 0.4745098 , 0.08235294],\n",
       "         [0.80784314, 0.4745098 , 0.08235294],\n",
       "         [0.80784314, 0.4745098 , 0.08235294],\n",
       "         ...,\n",
       "         [0.8       , 0.48235294, 0.10196078],\n",
       "         [0.80392157, 0.48627451, 0.10588235],\n",
       "         [0.80784314, 0.48627451, 0.11372549]],\n",
       "\n",
       "        [[0.80784314, 0.4745098 , 0.08235294],\n",
       "         [0.80784314, 0.4745098 , 0.08235294],\n",
       "         [0.80784314, 0.4745098 , 0.08235294],\n",
       "         ...,\n",
       "         [0.80392157, 0.48627451, 0.10588235],\n",
       "         [0.80392157, 0.48235294, 0.10980392],\n",
       "         [0.80784314, 0.48627451, 0.11372549]]],\n",
       "\n",
       "\n",
       "       [[[0.67843137, 0.51764706, 0.2745098 ],\n",
       "         [0.67843137, 0.51764706, 0.2745098 ],\n",
       "         [0.68235294, 0.52156863, 0.27843137],\n",
       "         ...,\n",
       "         [0.70980392, 0.55294118, 0.32156863],\n",
       "         [0.70980392, 0.55294118, 0.32156863],\n",
       "         [0.70588235, 0.54901961, 0.31764706]],\n",
       "\n",
       "        [[0.67843137, 0.51764706, 0.2745098 ],\n",
       "         [0.68235294, 0.52156863, 0.27843137],\n",
       "         [0.68235294, 0.52156863, 0.27843137],\n",
       "         ...,\n",
       "         [0.71372549, 0.55686275, 0.3254902 ],\n",
       "         [0.71372549, 0.55686275, 0.3254902 ],\n",
       "         [0.70980392, 0.55294118, 0.32156863]],\n",
       "\n",
       "        [[0.68235294, 0.52156863, 0.27843137],\n",
       "         [0.68235294, 0.5254902 , 0.28235294],\n",
       "         [0.68627451, 0.5254902 , 0.28235294],\n",
       "         ...,\n",
       "         [0.71372549, 0.55686275, 0.3254902 ],\n",
       "         [0.71372549, 0.55686275, 0.3254902 ],\n",
       "         [0.71372549, 0.55686275, 0.3254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03921569, 0.25882353, 0.27058824],\n",
       "         [0.05882353, 0.2745098 , 0.28235294],\n",
       "         [0.05098039, 0.27058824, 0.27843137],\n",
       "         ...,\n",
       "         [0.24313725, 0.35294118, 0.4745098 ],\n",
       "         [0.21568627, 0.31372549, 0.4627451 ],\n",
       "         [0.1372549 , 0.25882353, 0.35294118]],\n",
       "\n",
       "        [[0.05098039, 0.25490196, 0.26666667],\n",
       "         [0.04313725, 0.23921569, 0.25490196],\n",
       "         [0.0745098 , 0.2627451 , 0.27843137],\n",
       "         ...,\n",
       "         [0.22352941, 0.32156863, 0.47058824],\n",
       "         [0.09019608, 0.18039216, 0.36078431],\n",
       "         [0.15294118, 0.2627451 , 0.38823529]],\n",
       "\n",
       "        [[0.0745098 , 0.25882353, 0.26666667],\n",
       "         [0.02745098, 0.19607843, 0.19215686],\n",
       "         [0.02352941, 0.19607843, 0.19215686],\n",
       "         ...,\n",
       "         [0.16078431, 0.25490196, 0.4       ],\n",
       "         [0.2       , 0.3254902 , 0.4745098 ],\n",
       "         [0.12941176, 0.24705882, 0.37254902]]],\n",
       "\n",
       "\n",
       "       [[[0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         ...,\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333]],\n",
       "\n",
       "        [[0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         ...,\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333]],\n",
       "\n",
       "        [[0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         [0.6627451 , 0.38039216, 0.16862745],\n",
       "         ...,\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333],\n",
       "         [0.63529412, 0.34509804, 0.13333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.90196078, 0.76862745, 0.67843137],\n",
       "         [0.90196078, 0.76862745, 0.67843137],\n",
       "         [0.90196078, 0.76862745, 0.67843137],\n",
       "         ...,\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078]],\n",
       "\n",
       "        [[0.89803922, 0.76470588, 0.6745098 ],\n",
       "         [0.89803922, 0.76470588, 0.6745098 ],\n",
       "         [0.89803922, 0.76470588, 0.6745098 ],\n",
       "         ...,\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078]],\n",
       "\n",
       "        [[0.89411765, 0.75686275, 0.67843137],\n",
       "         [0.89411765, 0.75686275, 0.67843137],\n",
       "         [0.89411765, 0.75686275, 0.67843137],\n",
       "         ...,\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078],\n",
       "         [0.76470588, 0.49411765, 0.30196078]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sprite(X_train, sprite_path='./', p = 80):\n",
    "    m = X_train.shape[0]\n",
    "    #sprite will consist of n rows, n columns of mini-pictures, ordered row-first. Last row can be incomplete\n",
    "    n = int(math.sqrt(m))+1\n",
    "    assert n*80 <= 8192\n",
    "    sprite = np.zeros((n*80,n*80,3))\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    for r in range(m):\n",
    "        \n",
    "        sprite[i:i+p,j:j+p,:] = cv2.resize(X_train[r,:,:,:],(p,p))\n",
    "        #cv2.imwrite('debug.jpg',cv2.resize(X_train[r,:,:,:],(p,p)))\n",
    "        if (r+1)%n != 0:\n",
    "            j += p\n",
    "        else:\n",
    "            j = 0\n",
    "            i += p\n",
    "    sprite = (sprite*255).astype(int)\n",
    "    #weird: showimage requires floats from 0 to 1 (otherwise output is black)\n",
    "    #but for imwrite, values must be from 0 to 255 (otherwise, outputfile is entirely black)\n",
    "    #showimage(\"sprite\",sprite)\n",
    "    cv2.imwrite(os.path.join(sprite_path,'sprite.jpg'),sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_H0 -- scalar, height of an input image\n",
    "    n_W0 -- scalar, width of an input image\n",
    "    n_C0 -- scalar, number of channels of the input\n",
    "    n_y -- scalar, number of classes\n",
    "        \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (â‰ˆ2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape=(None,n_H0,n_W0,n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None,n_y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [4, 4, 3, 8]\n",
    "                        W2 : [2, 2, 8, 16]\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, W2\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   \n",
    "        \n",
    "\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "        W1 = tf.get_variable(\"W1\",[4,4,3,8],initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        W2 = tf.get_variable(\"W2\",[2, 2, 8, 16],initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"W2\": W2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"W2\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    with tf.name_scope(\"conv1\"):\n",
    "    # CONV2D: stride of 1, padding 'SAME'\n",
    "        Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "        # RELU\n",
    "        A1 = tf.nn.relu(Z1)\n",
    "    with tf.name_scope(\"maxpool1\"):\n",
    "        # MAXPOOL: window 8x8, sride 8, padding 'SAME'\n",
    "        P1 = tf.nn.max_pool(A1, ksize = [1,8,8,1], strides = [1,8,8,1], padding = 'SAME')\n",
    "    with tf.name_scope(\"conv2\"):    \n",
    "        # CONV2D: filters W2, stride 1, padding 'SAME'\n",
    "        Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "        # RELU\n",
    "        A2 = tf.nn.relu(Z2)\n",
    "    with tf.name_scope(\"maxpool2\"):\n",
    "        # MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "        P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "    with tf.name_scope(\"dense\"):\n",
    "        # FLATTEN\n",
    "        P3 = tf.contrib.layers.flatten(P2)\n",
    "        # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n",
    "        # 6 neurons in output layer. Hint: one of the arguments should be \"activation_fn=None\" \n",
    "        Z3 = tf.contrib.layers.fully_connected(P3, 3, activation_fn = None)\n",
    "    \n",
    "\n",
    "    return Z3, P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True,tensorboardpath=None,saved_model_path = None):\n",
    "    \"\"\"\n",
    "    Implements a three-layer ConvNet in Tensorflow:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_train -- test set, of shape (None, n_y = 6)\n",
    "    X_test -- training set, of shape (None, 64, 64, 3)\n",
    "    Y_test -- test set, of shape (None, n_y = 6)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    train_accuracy -- real number, accuracy on the train set (X_train)\n",
    "    test_accuracy -- real number, testing accuracy on the test set (X_test)\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    \n",
    "    # Create Placeholders of the correct shape\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3, P2 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "\n",
    "    if tensorboardpath is not None:\n",
    "        summary_cost = tf.summary.scalar('cost',cost)\n",
    "        summary_output = tf.summary.histogram('output',Z3)\n",
    "        merged_summary = tf.summary.merge_all()\n",
    "        \n",
    "        summary_images = tf.summary.image('training_images',X)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    #optimizer is an 'Operation' that updates the variables\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables globally\n",
    "    init = tf.global_variables_initializer()\n",
    "     \n",
    "    # Start the session to compute the tensorflow graph    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        \n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        \n",
    "        if tensorboardpath is not None:\n",
    "            filewriter_train = tf.summary.FileWriter(os.path.join(tensorboardpath,'train'),sess.graph)\n",
    "            filewriter_test = tf.summary.FileWriter(os.path.join(tensorboardpath,'test'),sess.graph)\n",
    "            #filewriter_embedding = tf.summary.FileWriter('./tensorboard_embedding/',sess.graph)\n",
    "            \n",
    "            image_summary = sess.run(summary_images,feed_dict={X: X_train, Y: Y_train})\n",
    "            filewriter_train.add_summary(image_summary)\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for i,minibatch in enumerate(minibatches):\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the optimizer and the cost, the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                \n",
    "                if tensorboardpath is not None:\n",
    "                    summary,_ , temp_cost = sess.run([summary_cost,optimizer,cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                    filewriter_train.add_summary(summary,epoch*num_minibatches+i)\n",
    "                else:\n",
    "                    _ , temp_cost = sess.run([optimizer,cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "                #evaluate train cost every MINIBATCH and display in tensorboard\n",
    "                #if tensorboardpath is not None:\n",
    "                #    filewriter_train.add_summary(summary,epoch*num_minibatches+i)\n",
    "                \n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "                \n",
    "            #evaluate test cost and test output histogram every EPOCH and display in tensorboard\n",
    "            if tensorboardpath is not None:           \n",
    "                summary = sess.run(merged_summary, feed_dict={X: X_test, Y: Y_test})\n",
    "                filewriter_test.add_summary(summary,(epoch+1)*num_minibatches)\n",
    "        \n",
    "                print(\"setting up tensorboard...\")\n",
    "                LOG_DIR = os.path.join(tensorboardpath,\"test\")\n",
    "        \n",
    "                z3 = sess.run(Z3,feed_dict={X: X_test, Y: Y_test})\n",
    "                embedding_var = tf.Variable(z3,  name='embedding')\n",
    "                #embedding_var is initialized with z3 values. Running this initialization in line below.\n",
    "                sess.run(embedding_var.initializer)\n",
    "                summary_writer = tf.summary.FileWriter(LOG_DIR)\n",
    "        \n",
    "                config = projector.ProjectorConfig()\n",
    "                embedding = config.embeddings.add()     \n",
    "                embedding.tensor_name = embedding_var.name\n",
    "        \n",
    "                print(\"creating sprite...\")\n",
    "                p=80 #thumbnail pixel size in sprite image.\n",
    "                create_sprite(X_test,sprite_path=LOG_DIR,p=p)        \n",
    "                #the path below must be relative to the directory of the filewriter. It is for example correct, if \n",
    "                #the path is sprite.jpg in the configfile, and configfile and sprite.jpg are in same folder\n",
    "                embedding.sprite.image_path = \"sprite.jpg\"\n",
    "                print(embedding.sprite.image_path)       \n",
    "                #Specify the width and height of a single thumbnail.\n",
    "                embedding.sprite.single_image_dim.extend([p, p])\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        #t.eval(feed_dict=None, session=None) is a shortcut for tf.get_default_session().run(t)\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "        \n",
    "        if tensorboardpath is not None:\n",
    "            print(\"creating metadata for embedding visualisation...\")\n",
    "            digit_to_label = {\"0\":\"car\",\"1\":\"plane\",\"2\":\"train\"}\n",
    "            with open(os.path.join(LOG_DIR,\"metadata.tsv\"), 'w') as f:\n",
    "                f.write(\"Index\\tLabel\\n\")\n",
    "                print(z3.shape)\n",
    "                print(np.argmax(z3,axis=1).astype(int).shape)\n",
    "                for index, digit in enumerate(list(np.argmax(z3,axis=1).astype(int))):\n",
    "                    f.write(\"{0}\\t{1}\\n\".format(index,digit_to_label[str(digit)])) \n",
    "            embedding.metadata_path = \"metadata.tsv\"\n",
    "\n",
    "            projector.visualize_embeddings(filewriter_test,config)\n",
    "            #projector.visualize_embeddings(summary_writer,config)\n",
    "            saver = tf.train.Saver([embedding_var])\n",
    "            saver.save(sess,os.path.join(LOG_DIR,\"model.ckpt\"))\n",
    "\n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        if saved_model_path is not None:\n",
    "            simple_save(sess,saved_model_path,inputs={\"X\":X},outputs={\"Z3\":Z3})\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation for tensorboard add_summary: https://www.tensorflow.org/versions/r1.5/api_docs/python/tf/summary/FileWriter#add_summary\n",
    "\n",
    "**You can pass the result of evaluating any SUMMARY op, using tf.Session.run or tf.Tensor.eval, to this function**\n",
    "\n",
    "Thus, you pass the result of evaluating a SUMMARY OPERATION, not just the result of evaluating an ordinary tensor. Type of summary variable is *bytes*, which can be passed to filewriter. Merging all can be handy, tf.summary.merge_all() is also a summary op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# conclusions\n",
    "\n",
    "High variance: train accuracy 100%, test accuracy approx. 80%\n",
    "\n",
    "Randomness in results of test accuracy: multiple percentage points! How is this possible??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.363143\n",
      "Cost after epoch 5: 0.872636\n",
      "Train Accuracy: 0.6958763\n",
      "Test Accuracy: 0.5846154\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: savedModel\\saved_model.pb\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-0b0879b592c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#without tensorboard, but with saving to SavedModel for serving\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaved_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEXPORT_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "#with tensorboard:\n",
    "#run_id += 1\n",
    "#_, _, parameters, sess = model(X_train, Y_train, X_test, Y_test,num_epochs=10,tensorboardpath=\"./tensorboard/{0}/\".format(run_id))\n",
    "\n",
    "EXPORT_DIR = \"savedModel\"\n",
    "\n",
    "#without tensorboard, but with saving to SavedModel for serving\n",
    "_, _, parameters, sess = model(X_train, Y_train, X_test, Y_test,num_epochs=10,saved_model_path = EXPORT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vreemde error hierboven?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to SavedModel\n",
    "\n",
    "Model was saved to SavedModel in EXPORT_DIR (by the function which creates the model.)\n",
    "\n",
    "savedModel was created with simple_save \n",
    "https://www.tensorflow.org/api_docs/python/tf/saved_model/simple_save\n",
    "Uses the tag tag_constants.SERVING. Supports the predict API. For Classify, Regress, or MultiInference APIs, use tf.Estimator or the lower level SavedModel API's. \n",
    "\n",
    "Below, we use tensorflow.contrib.predictor\n",
    "\n",
    "# Load SavedModel for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import predictor\n",
    "from tensorflow.saved_model import tag_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 256\n",
    "test_image = cv2.imread(\"images/car/img_2.jpg\")\n",
    "test_image = np.expand_dims(myImageLibrary.resize_crop(test_image,size),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from savedModel\\variables\\variables\n"
     ]
    }
   ],
   "source": [
    "predict_fn = predictor.from_saved_model(EXPORT_DIR)\n",
    "prediction = predict_fn({\"X\":test_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Z3': array([[ -79.092735, -388.82263 ,   26.819468]], dtype=float32)}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label = label_dict[str(np.argmax(prediction[\"Z3\"]))]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python352",
   "language": "python",
   "name": "python352"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
