{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"classifier-Keras.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"python352","language":"python","name":"python352"}},"cells":[{"metadata":{"id":"Pobk7lAdCgu-","colab_type":"text"},"cell_type":"markdown","source":["# 0 Imports"]},{"metadata":{"id":"hzr7iwYbCgu_","colab_type":"code","colab":{}},"cell_type":"code","source":["# keras imports\n","\n","import keras\n","from keras import layers\n","from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from keras.models import Model, load_model\n","from keras.preprocessing import image\n","from keras.utils import plot_model\n","from keras.initializers import glorot_uniform\n","import keras.backend as K\n","from keras.models import model_from_json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CLC9l0lACgvE","colab_type":"text"},"cell_type":"markdown","source":["**from tensorflow import keras**\n","tf.keras can run any keras-compatible code, but\n","1. version in latest TensorFlow may differ from latest Keras version in PyPi\n","2. when saving model weights, keras defaults to checkpoint format. For HDF5, pass save_format='h5'\n","\n","There might be some differences. \"from keras.utils.vis_utils import model_to_dot\" works but \"from tensorflow.keras.utils.vis_utils import model_to_dot\" doesn't."]},{"metadata":{"id":"HG5GlC6HCgvF","colab_type":"code","colab":{}},"cell_type":"code","source":["# tf.keras imports\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.initializers import glorot_uniform\n","import tensorflow.keras.backend as K\n","from tensorflow.keras.models import model_from_json"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ia5izgZECgvJ","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import pydot\n","from IPython.display import SVG\n","\n","import scipy.misc\n","from matplotlib.pyplot import imshow\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","import myImageLibrary\n","\n","K.set_image_data_format('channels_last')\n","K.set_learning_phase(1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NrXAuQPZCgvN","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.framework import ops\n","import matplotlib.pyplot as plt\n","import cv2\n","import glob\n","import os\n","import numpy as np\n","import math\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","\n","\n","\n","from matplotlib.pyplot import imshow\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7FlJLc4UCgvQ","colab_type":"code","colab":{}},"cell_type":"code","source":["def convert_to_one_hot(Y, C):\n","    Y = np.eye(C)[Y.reshape(-1)].T\n","    return Y"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YWoD0iT6CgvV","colab_type":"text"},"cell_type":"markdown","source":["# 1 Loading data"]},{"metadata":{"id":"IrJT-r-cCgvW","colab_type":"raw"},"cell_type":"markdown","source":["def showimage(title,img):\n","    cv2.imshow(title,img)\n","    cv2.waitKey(0)\n","    cv2.destroyAllWindows()\n","    \n","def crop_center(image,cropx,cropy):\n","    w = image.shape[1]\n","    h = image.shape[0]\n","    startx = w//2-(cropx//2)\n","    starty = h//2-(cropy//2)\n","    return image[starty:starty+cropy, startx:startx+cropx]\n","\n","def resize_crop(image,square_size):\n","    w = image.shape[1]\n","    h = image.shape[0]\n","    min_dim = min(w,h)  \n","    max_square_image = crop_center(image, min_dim, min_dim)\n","    result = cv2.resize(max_square_image,(square_size,square_size),0,0)\n","    return result\n","\n","\n","\n"]},{"metadata":{"id":"G4U2GZ1HCgvY","colab_type":"raw"},"cell_type":"markdown","source":["result_car = glob.glob('fotos_auto/*.jpg')+glob.glob('fotos_auto/*.jpeg')+glob.glob('fotos_auto/*.png')\n","images_car = [cv2.imread(item) for item in result_car]\n","print(len(images_car))\n","images_car = images_car[1:] #because first item appears to be None\n","\n","result_plane = glob.glob('fotos_vliegtuig/*.jpg')+glob.glob('fotos_vliegtuig/*.jpeg')+glob.glob('fotos_vliegtuig/*.png')\n","images_plane = [cv2.imread(item) for item in result_plane]\n","print(len(images_plane))\n","\n","result_train = glob.glob('fotos_trein/*.jpg')+glob.glob('fotos_trein/*.jpeg')+glob.glob('fotos_trein/*.png')\n","images_train = [cv2.imread(item) for item in result_train]\n","print(len(images_train))"]},{"metadata":{"id":"RjjSsKLECgvY","colab_type":"raw"},"cell_type":"markdown","source":["average_min_dim = 256"]},{"metadata":{"id":"zOvaA13nCgvZ","colab_type":"raw"},"cell_type":"markdown","source":["\n","\n","# rescaling and cropping images\n","\n","resized_images_car = np.array([resize_crop(item,average_min_dim) for item in images_car])\n","resized_images_plane = np.array([resize_crop(item,average_min_dim) for item in images_plane])\n","resized_images_train = np.array([resize_crop(item,average_min_dim) for item in images_train])"]},{"metadata":{"id":"P5WRLZ7PCgva","colab_type":"raw"},"cell_type":"markdown","source":["# combine all data, labels, normalize\n","\n","input_images = np.append(np.append(resized_images_car,resized_images_plane,axis=0),resized_images_train,axis=0)/255\n","labels = np.array([0] * resized_images_car.shape[0] + [1] * resized_images_plane.shape[0] + [2] * resized_images_train.shape[0])\n","labels = np.reshape(labels,(-1,1))\n","outputy = convert_to_one_hot(labels,3).T\n","\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(input_images,outputy)\n","\n","imshow(X_train[len(X_train)-1])"]},{"metadata":{"id":"HSYdFDVtCgvb","colab_type":"raw"},"cell_type":"markdown","source":["np.save('input_images.npy',input_images)\n","np.save('outputy.npy',outputy)"]},{"metadata":{"id":"BHZ2ebZuCgvd","colab_type":"raw"},"cell_type":"markdown","source":["input_images = np.load(\"input_images.npy\")\n","outputy = np.load(\"outputy.npy\")"]},{"metadata":{"id":"D1X4VUAsCgve","colab_type":"raw"},"cell_type":"markdown","source":["#basic data augmentation: vertical mirroring\n","\n","X_train_flipped = X_train[:,:,::-1,:]\n","\n","X_train_augm=np.append(X_train,X_train_flipped,axis=0)\n","Y_train_flipped = Y_train\n","Y_train_augm = np.append(Y_train,Y_train_flipped,axis=0)\n","\n","imshow(X_train_augm[len(X_train_augm)-1])"]},{"metadata":{"id":"EYh2spa8Cgvk","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_classifier_data(image_folder, size = 256, verbose = True, mode = \"channels_first\",one_hot = False):\n","    \n","    folders = os.listdir(\"images\")\n","    if verbose:\n","        print(\"classes: {0}\".format(folders))\n","    input_labels = []\n","    input_data = []\n","    label_dict = {}\n","\n","    for i, folder in enumerate(folders):\n","        if verbose:\n","            print(\"{0}..\".format(folder))   \n","        image_list = myImageLibrary.get_images(os.path.join(\"images\",folder))\n","        if mode == \"channels_first\":\n","            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size).transpose(2,0,1)/255.0,decimals=12) for image in image_list]\n","        elif mode == \"channels_last\":\n","            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size)/255.0,decimals=12) for image in image_list]\n","        else:\n","            print(\"invalid mode. pick channels_first or channels_last\")\n","        # processed = normalized, resized and cropped, transposed to \"channels first\"\n","        input_labels = input_labels+([i]*len(processed_image_list))\n","        input_data = input_data+processed_image_list\n","        label_dict[str(i)] = folder\n","        \n","    shape = list(input_data[0].shape)\n","    shape[:0] = [len(input_data)]\n","    input_array = np.concatenate(input_data).reshape(shape)\n","    \n","    input_labels = np.array(input_labels)\n","    \n","    if one_hot:\n","        input_labels = convert_to_one_hot(np.array(input_labels),len(folders)).T\n","            \n","    return input_array, input_labels, label_dict\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"_YeN41-nCgvr","colab_type":"code","colab":{},"outputId":"c4bdd098-8286-47d4-9a02-2a8ca4d4ca0a"},"cell_type":"code","source":["image_folder = \"images\"\n","size = 256\n","mode = \"channels_last\"\n","input_images, labels, label_dict = get_classifier_data(image_folder,mode=mode,one_hot = True,size=size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["classes: ['car', 'plane', 'train']\n","car..\n","plane..\n","train..\n"],"name":"stdout"}]},{"metadata":{"id":"GxCi1yI9Cgv0","colab_type":"code","colab":{},"outputId":"862a85b3-0a57-4ca2-ad84-e2d9b0ab2d92"},"cell_type":"code","source":["print(input_images.shape)\n","print(labels.shape)\n","print(label_dict)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(518, 256, 256, 3)\n","(518, 3)\n","{'2': 'train', '1': 'plane', '0': 'car'}\n"],"name":"stdout"}]},{"metadata":{"id":"3H95Ic-VCgv3","colab_type":"text"},"cell_type":"markdown","source":["# 2 Building Keras model and testing"]},{"metadata":{"id":"_UqC4U-ACgv5","colab_type":"text"},"cell_type":"markdown","source":["## 2.1 Train/test split"]},{"metadata":{"id":"ECd3o8cpCgv6","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(input_images,labels)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"79U8ohMOCgwA","colab_type":"code","colab":{},"outputId":"8bea476c-4ee4-44c6-f527-18cd2b0cf419"},"cell_type":"code","source":["print(input_images.shape)\n","print(labels.shape)\n","print(X_train.shape)\n","print(X_test.shape)\n","print(Y_train.shape)\n","print(Y_test.shape)\n","print('----')\n","\n","#print(X_train_augm.shape)\n","#print(Y_train_augm.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(518, 256, 256, 3)\n","(518, 3)\n","(388, 256, 256, 3)\n","(130, 256, 256, 3)\n","(388, 3)\n","(130, 3)\n","----\n"],"name":"stdout"}]},{"metadata":{"id":"SJUM12WzCgwF","colab_type":"text"},"cell_type":"markdown","source":["## 2.2  model 1"]},{"metadata":{"id":"F65DXnpfCgwG","colab_type":"code","colab":{}},"cell_type":"code","source":["# This model is shaped just like the one implemented directly in TensorFlow (see classifier-convNet)\n","\n","def ModelCarPlaneTrain(input_shape = (256,256,3), classes = 3):\n","    \n","    X_input = Input(input_shape)\n","    \n","    X = Conv2D(8,(4,4),strides = (1,1),name='conv1',kernel_initializer = glorot_uniform(seed=0))(X_input)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((8, 8))(X)\n","    \n","    X = Conv2D(16,(2,2),strides = (1,1),name='conv2',kernel_initializer = glorot_uniform(seed=0))(X)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((4, 4))(X)\n","    \n","    X = Flatten()(X)\n","    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = glorot_uniform(seed=0))(X)\n","    \n","    model = Model(inputs = X_input, outputs = X, name = 'ModelCarPlaneTrain-2layer')\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2AZnkaOJCgwL","colab_type":"code","colab":{}},"cell_type":"code","source":["model_1 = ModelCarPlaneTrain(input_shape=(size,size,3))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L13a2tLLCgwN","colab_type":"code","colab":{}},"cell_type":"code","source":["model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YRN_vKIpCgwQ","colab_type":"code","colab":{},"outputId":"b0e35124-d0a0-44c4-8036-ab790316fa5a"},"cell_type":"code","source":["model_1.fit(X_train,Y_train, epochs = 1, batch_size = 64)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","388/388 [==============================] - 110s 283ms/step - loss: 1.0945 - acc: 0.4253\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2540b1dbe10>"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"I-lhONRwCgwU","colab_type":"code","colab":{},"outputId":"e36a874e-0ddf-4286-a3c2-53607dcfcd15"},"cell_type":"code","source":["preds_1 = model_1.evaluate(X_test,Y_test)\n","print (\"Loss = \" + str(preds_1[0]))\n","print (\"Test Accuracy = \" + str(preds_1[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["130/130 [==============================] - 1s 10ms/step\n","Loss = 1.0909130499913142\n","Test Accuracy = 0.3230769230769231\n"],"name":"stdout"}]},{"metadata":{"id":"I5k_3TeKCgwX","colab_type":"text"},"cell_type":"markdown","source":["## 2.3 model 2"]},{"metadata":{"id":"mZkErYKMCgwY","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["# This model is less complex and has same accuracy\n","\n","def ModelCarPlaneTrain_2(input_shape = (256,256,3), classes = 3):\n","    \n","    X_input = Input(input_shape)\n","    \n","    X = Conv2D(8,(4,4),strides = (1,1),name='conv1',kernel_initializer = glorot_uniform(seed=0))(X_input)\n","    X = Activation('relu')(X)\n","    X = MaxPooling2D((16, 16))(X)\n","    \n","    #X = Conv2D(32,(2,2),strides = (1,1),name='conv2',kernel_initializer = glorot_uniform(seed=0))(X)\n","    #X = Activation('relu')(X)\n","    #X = MaxPooling2D((4, 4))(X)\n","    \n","    X = Flatten()(X)\n","    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = glorot_uniform(seed=0))(X)\n","    \n","    model = Model(inputs = X_input, outputs = X, name = 'ModelCarPlaneTrain-2layer')\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-XqdquAVCgwd","colab_type":"code","colab":{},"outputId":"52c8672c-bdcf-4317-f503-a1235d855ea6"},"cell_type":"code","source":["model_2 = ModelCarPlaneTrain_2(input_shape=(size,size,3))\n","model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#without augmentation\n","model_2.fit(X_train,Y_train, epochs = 1, batch_size = 16)\n","\n","#note: when switching, do not fit model twice (ensure correct comparison) (won't happen when re-running this cell)\n","\n","#with augmentation (vertical mirroring)\n","#model_2.fit(X_train_augm,Y_train_augm, epochs = 60, batch_size = 16)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/1\n","388/388 [==============================] - 9s 22ms/step - loss: 0.9500 - acc: 0.5284\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x2540b48d0b8>"]},"metadata":{"tags":[]},"execution_count":20}]},{"metadata":{"id":"WnaY0TEECgwi","colab_type":"code","colab":{},"outputId":"796edd08-27d1-48e9-ef45-8cfcc09b88ba"},"cell_type":"code","source":["preds_2 = model_2.evaluate(X_test,Y_test)\n","print (\"Loss = \" + str(preds_2[0]))\n","print (\"Test Accuracy = \" + str(preds_2[1]))\n","\n","#augmentation does not seem to improve accuracy significantly"],"execution_count":0,"outputs":[{"output_type":"stream","text":["130/130 [==============================] - 1s 10ms/step\n","Loss = 0.8378040020282452\n","Test Accuracy = 0.6307692307692307\n"],"name":"stdout"}]},{"metadata":{"id":"UweZkJBbCgwm","colab_type":"text"},"cell_type":"markdown","source":["## 2.4 exporting and loading of keras model"]},{"metadata":{"id":"pW9R_tF2Cgwm","colab_type":"text"},"cell_type":"markdown","source":["**2.4.1 Method 1 (model and weights in seperate files) **"]},{"metadata":{"id":"Wop3CPVoCgwm","colab_type":"text"},"cell_type":"markdown","source":["We are passing save_format='h5' explicitly, because when using tf.keras it would default to TensorFlow's checkpoint format."]},{"metadata":{"id":"8iYr7e00Cgwo","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["#exporting the second model to json\n","\n","model_2_json = model_2.to_json()\n","with open(\"keras_model_2.json\",\"w\") as file:\n","    file.write(model_2_json)   \n","model_2.save_weights(\"keras_model_2.h5\",save_format='h5')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GMC7c-BoCgwq","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["#loading and using model\n","\n","file = open('keras_model_2.json', 'r')\n","loaded_model_2_json = file.read()\n","file.close()\n","loaded_model_2 = model_from_json(loaded_model_2_json)\n","loaded_model_2.load_weights(\"keras_model_2.h5\")\n","\n","loaded_model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K-9Kvs21Cgwt","colab_type":"code","colab":{},"outputId":"11fd2925-62f4-43b4-fc0c-a7b56b027c22"},"cell_type":"code","source":["preds = loaded_model_2.evaluate(X_test,Y_test)\n","print (\"Loss = \" + str(preds[0]))\n","print (\"Test Accuracy = \" + str(preds[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["130/130 [==============================] - 1s 10ms/step\n","Loss = 0.8378040020282452\n","Test Accuracy = 0.6307692307692307\n"],"name":"stdout"}]},{"metadata":{"id":"kiwrhGI7Cgwx","colab_type":"text"},"cell_type":"markdown","source":["**2.4.1 Method 2 (model and weights in one file, easier)**"]},{"metadata":{"id":"Gg54FD0BCgwx","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["keras.models.save_model(model_2,\"keras_model_2_full.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-qa7CiyECgw0","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["loaded_model_2 = load_model(\"keras_model_2_full.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0YZBaKLkCgw4","colab_type":"code","colab":{},"outputId":"68ddf914-c3c7-4413-a990-5ddabb473924"},"cell_type":"code","source":["preds = loaded_model_2.evaluate(X_test,Y_test)\n","print (\"Loss = \" + str(preds[0]))\n","print (\"Test Accuracy = \" + str(preds[1]))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["130/130 [==============================] - 1s 10ms/step\n","Loss = 0.8378040020282452\n","Test Accuracy = 0.6307692307692307\n"],"name":"stdout"}]},{"metadata":{"id":"XhE1ZCYwCgw_","colab_type":"text"},"cell_type":"markdown","source":["# 3 Autokeras"]},{"metadata":{"id":"w-8vEtQaCgxA","colab_type":"text"},"cell_type":"markdown","source":["## 3.1 Just structuring the data in the Autokeras way... REMOVE THIS FROM TRAINING VERSION\n","\n","Images must be in one folder, and a csv-file is required with header \"File Name, Label\" that maps file names to label strings. Images must all have equal pixel size, otherwise load_image_dataset() will not raise error but will return a wrong result (a numpy array of numpy arrays) so that fitting fails."]},{"metadata":{"id":"pONQSvV7CgxB","colab_type":"text"},"cell_type":"markdown","source":["First, copying all seperate image folders and renaming these folders to to \"..._renamed\""]},{"metadata":{"id":"wu-kyVz0CgxC","colab_type":"raw"},"cell_type":"markdown","source":["import glob\n","import os"]},{"metadata":{"id":"_Cw24x0uCgxD","colab_type":"raw"},"cell_type":"markdown","source":["filenames_car = glob.glob('fotos_auto_renamed/*.jpg')+glob.glob('fotos_auto_renamed/*.jpeg')+glob.glob('fotos_auto_renamed/*.png')\n","filenames_plane = glob.glob('fotos_vliegtuig_renamed/*.jpg')+glob.glob('fotos_vliegtuig_renamed/*.jpeg')+glob.glob('fotos_vliegtuig_renamed/*.png')\n","filenames_train = glob.glob('fotos_trein_renamed/*.jpg')+glob.glob('fotos_trein_renamed/*.jpeg')+glob.glob('fotos_trein_renamed/*.png')\n","\n","with open(\"labels.csv\", 'a') as label_file:\n","    label_file.write(\"File Name,Label\\n\")\n","    for filename in filenames_car:\n","        os.rename(filename, filename.split('\\\\')[0]+'\\\\car_'+filename.split('\\\\')[1])\n","        label_file.write(\"{0},{1}\\n\".format(\"car_\"+filename.split('\\\\')[1],'car'))\n","    for filename in filenames_plane:\n","        os.rename(filename, filename.split('\\\\')[0]+'\\\\plane_'+filename.split('\\\\')[1])\n","        label_file.write(\"{0},{1}\\n\".format(\"plane_\"+filename.split('\\\\')[1],'plane'))\n","    for filename in filenames_train:\n","        os.rename(filename, filename.split('\\\\')[0]+'\\\\train_'+filename.split('\\\\')[1])\n","        label_file.write(\"{0},{1}\\n\".format(\"train_\"+filename.split('\\\\')[1],'train'))"]},{"metadata":{"id":"1O6F6oQWCgxD","colab_type":"text"},"cell_type":"markdown","source":["Now add all files to one folder images_all/"]},{"metadata":{"id":"nmy-zdpbCgxF","colab_type":"raw"},"cell_type":"markdown","source":["for filename in glob.glob('images_all/*'):\n","    raw_image = cv2.imread(filename)\n","    resized_image = resize_crop(raw_image,256)\n","    cv2.imwrite(filename,resized_image)"]},{"metadata":{"id":"5Kpv1HHYCgxF","colab_type":"text"},"cell_type":"markdown","source":["test1 = cv2.imread(glob.glob('images_all/*')[1])\n","test2 = cv2.imread(glob.glob('images_all/*')[2])\n","print(test1.shape)\n","print(test2.shape)"]},{"metadata":{"id":"E7UjgQW2CgxG","colab_type":"text"},"cell_type":"markdown","source":["## 3.2 Building and training Autokeras model\n","\n","I have run code below for several hours. Did not stop after time limit and also produced disappointing results."]},{"metadata":{"id":"_uw1UkU6CgxG","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["import autokeras as ak\n","from autokeras.classifier import ImageClassifier,load_image_dataset\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2wr0OEafCgxJ","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["X, Y = load_image_dataset(csv_file_path=\"labels.csv\",images_path=\"images_all\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qVzsLFF0CgxL","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wwJ3HqYnCgxP","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["classifier = ImageClassifier(verbose=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KiG-STmqCgxT","colab_type":"code","colab":{},"outputId":"5c278556-2fc7-47d7-b240-20b96e7199b4"},"cell_type":"code","source":["classifier.fit(X_train,Y_train,time_limit = 2 * 60 * 60)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Initializing search.\n","Initialization finished.\n","Training model  0\n","Saving model.\n","Model ID: 0\n","Loss: 0.7097633161495641\n","Accuracy 0.6082474226804123\n","Training model  1\n","Father ID:  0\n","[('to_add_skip_model', 1, 6), ('to_wider_model', 6, 64), ('to_concat_skip_model', 1, 6)]\n"],"name":"stdout"}]},{"metadata":{"id":"Asfy07VkCgxY","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["classifier.final_fit(X_train,Y_train, X_test, Y_test, retrain=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"c7UbULJTCgxb","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["y = classifier.evaluate(X_test, Y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E_ebz9azCgxf","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":["print(time.time())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3eKglXkeCgxh","colab_type":"code","colab":{},"collapsed":true},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}