{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras imports\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**from tensorflow import keras**\n",
    "tf.keras can run any keras-compatible code, but\n",
    "1. version in latest TensorFlow may differ from latest Keras version in PyPi\n",
    "2. when saving model weights, keras defaults to checkpoint format. For HDF5, pass save_format='h5'\n",
    "\n",
    "There might be some differences. \"from keras.utils.vis_utils import model_to_dot\" works but \"from tensorflow.keras.utils.vis_utils import model_to_dot\" doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.keras imports\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import myImageLibrary\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Loading data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def showimage(title,img):\n",
    "    cv2.imshow(title,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def crop_center(image,cropx,cropy):\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    startx = w//2-(cropx//2)\n",
    "    starty = h//2-(cropy//2)\n",
    "    return image[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "def resize_crop(image,square_size):\n",
    "    w = image.shape[1]\n",
    "    h = image.shape[0]\n",
    "    min_dim = min(w,h)  \n",
    "    max_square_image = crop_center(image, min_dim, min_dim)\n",
    "    result = cv2.resize(max_square_image,(square_size,square_size),0,0)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result_car = glob.glob('fotos_auto/*.jpg')+glob.glob('fotos_auto/*.jpeg')+glob.glob('fotos_auto/*.png')\n",
    "images_car = [cv2.imread(item) for item in result_car]\n",
    "print(len(images_car))\n",
    "images_car = images_car[1:] #because first item appears to be None\n",
    "\n",
    "result_plane = glob.glob('fotos_vliegtuig/*.jpg')+glob.glob('fotos_vliegtuig/*.jpeg')+glob.glob('fotos_vliegtuig/*.png')\n",
    "images_plane = [cv2.imread(item) for item in result_plane]\n",
    "print(len(images_plane))\n",
    "\n",
    "result_train = glob.glob('fotos_trein/*.jpg')+glob.glob('fotos_trein/*.jpeg')+glob.glob('fotos_trein/*.png')\n",
    "images_train = [cv2.imread(item) for item in result_train]\n",
    "print(len(images_train))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "average_min_dim = 256"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "# rescaling and cropping images\n",
    "\n",
    "resized_images_car = np.array([resize_crop(item,average_min_dim) for item in images_car])\n",
    "resized_images_plane = np.array([resize_crop(item,average_min_dim) for item in images_plane])\n",
    "resized_images_train = np.array([resize_crop(item,average_min_dim) for item in images_train])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# combine all data, labels, normalize\n",
    "\n",
    "input_images = np.append(np.append(resized_images_car,resized_images_plane,axis=0),resized_images_train,axis=0)/255\n",
    "labels = np.array([0] * resized_images_car.shape[0] + [1] * resized_images_plane.shape[0] + [2] * resized_images_train.shape[0])\n",
    "labels = np.reshape(labels,(-1,1))\n",
    "outputy = convert_to_one_hot(labels,3).T\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(input_images,outputy)\n",
    "\n",
    "imshow(X_train[len(X_train)-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.save('input_images.npy',input_images)\n",
    "np.save('outputy.npy',outputy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "input_images = np.load(\"input_images.npy\")\n",
    "outputy = np.load(\"outputy.npy\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#basic data augmentation: vertical mirroring\n",
    "\n",
    "X_train_flipped = X_train[:,:,::-1,:]\n",
    "\n",
    "X_train_augm=np.append(X_train,X_train_flipped,axis=0)\n",
    "Y_train_flipped = Y_train\n",
    "Y_train_augm = np.append(Y_train,Y_train_flipped,axis=0)\n",
    "\n",
    "imshow(X_train_augm[len(X_train_augm)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_classifier_data(image_folder, size = 256, verbose = True, mode = \"channels_first\",one_hot = False):\n",
    "    \n",
    "    folders = os.listdir(\"images\")\n",
    "    if verbose:\n",
    "        print(\"classes: {0}\".format(folders))\n",
    "    input_labels = []\n",
    "    input_data = []\n",
    "    label_dict = {}\n",
    "\n",
    "    for i, folder in enumerate(folders):\n",
    "        if verbose:\n",
    "            print(\"{0}..\".format(folder))   \n",
    "        image_list = myImageLibrary.get_images(os.path.join(\"images\",folder))\n",
    "        if mode == \"channels_first\":\n",
    "            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size).transpose(2,0,1)/255.0,decimals=12) for image in image_list]\n",
    "        elif mode == \"channels_last\":\n",
    "            processed_image_list =  [np.around(myImageLibrary.resize_crop(image,size)/255.0,decimals=12) for image in image_list]\n",
    "        else:\n",
    "            print(\"invalid mode. pick channels_first or channels_last\")\n",
    "        # processed = normalized, resized and cropped, transposed to \"channels first\"\n",
    "        input_labels = input_labels+([i]*len(processed_image_list))\n",
    "        input_data = input_data+processed_image_list\n",
    "        label_dict[str(i)] = folder\n",
    "        \n",
    "    shape = list(input_data[0].shape)\n",
    "    shape[:0] = [len(input_data)]\n",
    "    input_array = np.concatenate(input_data).reshape(shape)\n",
    "    \n",
    "    input_labels = np.array(input_labels)\n",
    "    \n",
    "    if one_hot:\n",
    "        input_labels = convert_to_one_hot(np.array(input_labels),len(folders)).T\n",
    "            \n",
    "    return input_array, input_labels, label_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['car', 'plane', 'train']\n",
      "car..\n",
      "plane..\n",
      "train..\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"images\"\n",
    "size = 256\n",
    "mode = \"channels_last\"\n",
    "input_images, labels, label_dict = get_classifier_data(image_folder,mode=mode,one_hot = True,size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 256, 256, 3)\n",
      "(518, 3)\n",
      "{'2': 'train', '1': 'plane', '0': 'car'}\n"
     ]
    }
   ],
   "source": [
    "print(input_images.shape)\n",
    "print(labels.shape)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Building Keras model and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(input_images,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 256, 256, 3)\n",
      "(518, 3)\n",
      "(388, 256, 256, 3)\n",
      "(130, 256, 256, 3)\n",
      "(388, 3)\n",
      "(130, 3)\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print(input_images.shape)\n",
    "print(labels.shape)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print('----')\n",
    "\n",
    "#print(X_train_augm.shape)\n",
    "#print(Y_train_augm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This model is shaped just like the one implemented directly in TensorFlow (see classifier-convNet)\n",
    "\n",
    "def ModelCarPlaneTrain(input_shape = (256,256,3), classes = 3):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(8,(4,4),strides = (1,1),name='conv1',kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((8, 8))(X)\n",
    "    \n",
    "    X = Conv2D(16,(2,2),strides = (1,1),name='conv2',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((4, 4))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = 'ModelCarPlaneTrain-2layer')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = ModelCarPlaneTrain(input_shape=(size,size,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "388/388 [==============================] - 110s 283ms/step - loss: 1.0945 - acc: 0.4253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2540b1dbe10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train,Y_train, epochs = 1, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 10ms/step\n",
      "Loss = 1.0909130499913142\n",
      "Test Accuracy = 0.3230769230769231\n"
     ]
    }
   ],
   "source": [
    "preds_1 = model_1.evaluate(X_test,Y_test)\n",
    "print (\"Loss = \" + str(preds_1[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This model is less complex and has same accuracy\n",
    "\n",
    "def ModelCarPlaneTrain_2(input_shape = (256,256,3), classes = 3):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = Conv2D(8,(4,4),strides = (1,1),name='conv1',kernel_initializer = glorot_uniform(seed=0))(X_input)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((16, 16))(X)\n",
    "    \n",
    "    #X = Conv2D(32,(2,2),strides = (1,1),name='conv2',kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    #X = Activation('relu')(X)\n",
    "    #X = MaxPooling2D((4, 4))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name = 'ModelCarPlaneTrain-2layer')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "388/388 [==============================] - 9s 22ms/step - loss: 0.9500 - acc: 0.5284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2540b48d0b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = ModelCarPlaneTrain_2(input_shape=(size,size,3))\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#without augmentation\n",
    "model_2.fit(X_train,Y_train, epochs = 1, batch_size = 16)\n",
    "\n",
    "#note: when switching, do not fit model twice (ensure correct comparison) (won't happen when re-running this cell)\n",
    "\n",
    "#with augmentation (vertical mirroring)\n",
    "#model_2.fit(X_train_augm,Y_train_augm, epochs = 60, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 10ms/step\n",
      "Loss = 0.8378040020282452\n",
      "Test Accuracy = 0.6307692307692307\n"
     ]
    }
   ],
   "source": [
    "preds_2 = model_2.evaluate(X_test,Y_test)\n",
    "print (\"Loss = \" + str(preds_2[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_2[1]))\n",
    "\n",
    "#augmentation does not seem to improve accuracy significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 exporting and loading of keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.1 Method 1 (model and weights in seperate files) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are passing save_format='h5' explicitly, because when using tf.keras it would default to TensorFlow's checkpoint format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exporting the second model to json\n",
    "\n",
    "model_2_json = model_2.to_json()\n",
    "with open(\"keras_model_2.json\",\"w\") as file:\n",
    "    file.write(model_2_json)   \n",
    "model_2.save_weights(\"keras_model_2.h5\",save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading and using model\n",
    "\n",
    "file = open('keras_model_2.json', 'r')\n",
    "loaded_model_2_json = file.read()\n",
    "file.close()\n",
    "loaded_model_2 = model_from_json(loaded_model_2_json)\n",
    "loaded_model_2.load_weights(\"keras_model_2.h5\")\n",
    "\n",
    "loaded_model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 10ms/step\n",
      "Loss = 0.8378040020282452\n",
      "Test Accuracy = 0.6307692307692307\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model_2.evaluate(X_test,Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4.1 Method 2 (model and weights in one file, easier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.models.save_model(model_2,\"keras_model_2_full.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_model_2 = load_model(\"keras_model_2_full.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 1s 10ms/step\n",
      "Loss = 0.8378040020282452\n",
      "Test Accuracy = 0.6307692307692307\n"
     ]
    }
   ],
   "source": [
    "preds = loaded_model_2.evaluate(X_test,Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Just structuring the data in the Autokeras way... REMOVE THIS FROM TRAINING VERSION\n",
    "\n",
    "Images must be in one folder, and a csv-file is required with header \"File Name, Label\" that maps file names to label strings. Images must all have equal pixel size, otherwise load_image_dataset() will not raise error but will return a wrong result (a numpy array of numpy arrays) so that fitting fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, copying all seperate image folders and renaming these folders to to \"..._renamed\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filenames_car = glob.glob('fotos_auto_renamed/*.jpg')+glob.glob('fotos_auto_renamed/*.jpeg')+glob.glob('fotos_auto_renamed/*.png')\n",
    "filenames_plane = glob.glob('fotos_vliegtuig_renamed/*.jpg')+glob.glob('fotos_vliegtuig_renamed/*.jpeg')+glob.glob('fotos_vliegtuig_renamed/*.png')\n",
    "filenames_train = glob.glob('fotos_trein_renamed/*.jpg')+glob.glob('fotos_trein_renamed/*.jpeg')+glob.glob('fotos_trein_renamed/*.png')\n",
    "\n",
    "with open(\"labels.csv\", 'a') as label_file:\n",
    "    label_file.write(\"File Name,Label\\n\")\n",
    "    for filename in filenames_car:\n",
    "        os.rename(filename, filename.split('\\\\')[0]+'\\\\car_'+filename.split('\\\\')[1])\n",
    "        label_file.write(\"{0},{1}\\n\".format(\"car_\"+filename.split('\\\\')[1],'car'))\n",
    "    for filename in filenames_plane:\n",
    "        os.rename(filename, filename.split('\\\\')[0]+'\\\\plane_'+filename.split('\\\\')[1])\n",
    "        label_file.write(\"{0},{1}\\n\".format(\"plane_\"+filename.split('\\\\')[1],'plane'))\n",
    "    for filename in filenames_train:\n",
    "        os.rename(filename, filename.split('\\\\')[0]+'\\\\train_'+filename.split('\\\\')[1])\n",
    "        label_file.write(\"{0},{1}\\n\".format(\"train_\"+filename.split('\\\\')[1],'train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add all files to one folder images_all/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for filename in glob.glob('images_all/*'):\n",
    "    raw_image = cv2.imread(filename)\n",
    "    resized_image = resize_crop(raw_image,256)\n",
    "    cv2.imwrite(filename,resized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test1 = cv2.imread(glob.glob('images_all/*')[1])\n",
    "test2 = cv2.imread(glob.glob('images_all/*')[2])\n",
    "print(test1.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Building and training Autokeras model\n",
    "\n",
    "I have run code below for several hours. Did not stop after time limit and also produced disappointing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "from autokeras.classifier import ImageClassifier,load_image_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = load_image_dataset(csv_file_path=\"labels.csv\",images_path=\"images_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = ImageClassifier(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing search.\n",
      "Initialization finished.\n",
      "Training model  0\n",
      "Saving model.\n",
      "Model ID: 0\n",
      "Loss: 0.7097633161495641\n",
      "Accuracy 0.6082474226804123\n",
      "Training model  1\n",
      "Father ID:  0\n",
      "[('to_add_skip_model', 1, 6), ('to_wider_model', 6, 64), ('to_concat_skip_model', 1, 6)]\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train,time_limit = 2 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.final_fit(X_train,Y_train, X_test, Y_test, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = classifier.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python352",
   "language": "python",
   "name": "python352"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
